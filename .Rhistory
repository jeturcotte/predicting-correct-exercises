set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subset <- training[,grep("^IL", colnames(training))]
training
colnames(training)
subset <- training[,grep("^IL", colnames(training) | "diagnosis")]
subset <- training[,grep("^IL", colnames(training) || "diagnosis")]
subset <- training[,grep("^IL|^diagnosis$", colnames(training))]
colnames(subset)
preProc <- preProcess(log10(subset), method="pca")
preProc <- preProcess(log10(subset[,-1]), method="pca")
subset[,-1]
preProc <- preProcess(log10(subset[,-1]), method="pca", pcaComp=12)
preProc <- preProcess(log10(subset[,-1]), method="pca", pcaComp=2)
preProc <- preProcess(subset[,-1], method="pca", pcaComp=2)
preProc <- preProcess(subset[,-1], method="pca", pcaComp=12)
preProc
tpc <- predict(preProc, subset[,-1])
fit <- train(diagnosis ~ ., method="glm", data=subset)
library(e1071)
install.packages("e1071")
library(e1071)
fit <- train(diagnosis ~ ., method="glm", data=subset)
fit
confusionMatrix(subset$diagnosis, predict(fit, tpc))
subset
fit <- train(diagnosis ~ ., method="glm", preProcess="pca", data=subset)
confusionMatrix(subset$diagnosis, predict(fit, subset))
pca <- princomp(subset)
pca <- princomp(subset[,-1])
summary(pca)
fitata <- lm(diagnosis ~ ., subset)
fitata
fit <- train(diagnosis ~ ., method="glm", preProcess="pca", data=subset)
confusionMatrix(fitata)
fitata
fit
fitata <- train(diagnosis ~ ., method="glm", data=subset)
fitata
confusionMatrix(fitata)
confusionMatrix(fit)
subset <- training[,grep("^IL|^diagnosis$", colnames(training))]
tsubset <- testing[,grep("^IL|^diagnosis$", colnames(training))]
fit_ata <- train(diagnosis ~ ., method="glm", data=subset)
fit_pca <- train(diagnosis ~ ., method="glm", preProcess="pca", data=subset)
confusionMatrix(testing, predict(fit_ata, testing))
confusionMatrix(testing$diagnosis, predict(fit_ata, testing))
confusionMatrix(testing$diagnosis, predict(fit_pca, testing))
library(caret)library(AppliedPredictiveModeling)set.seed(3433)data(AlzheimerDisease)adData = data.frame(diagnosis,predictors)inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
adData
inTrain = createDataPartition( adData$diagnosis, p=3/4)[[1]]
inTrain
training = adData[,inTrain.]
training = adData[,inTrain,]
training = adData[inTrain,]
testing = adData[-inTrain,]
testing
qplot(diagnosis, color=genotype, data=training, geom="density")
qplot(diagnosis, color=Genotype, data=training, geom="density")
colnames(training)
qplot(diagnosis, color=IL_11, data=training, geom="density")
qplot(diagnosis, color=IL_17E, data=training, geom="density")
qplot(diagnosis, color=Insulin, data=training, geom="density")
qplot(diagnosis, color=taun, data=training, geom="density")
qplot(diagnosis, color=tau, data=training, geom="density")
qplot(diagnosis, color=Genotype, data=training, geom="density")
subset_w_diagnosis <- training[,grep("^IL|^diagnosis$", colnames(training))]
subset <- training[,grep("^IL", colnames(training))]
colanmes(subset)
colnames(subset)
colnames(subset_w_diagnosis)
?preProcess
pp <- preProcess(subset)
pp
summary(pp)
pp <- preProcess(subset, method=c("center","scale"))
pp
ppp <- predict(pp,subset)
mean(ppp)
ppp
apply(ppp,mean)
fit <- train(1 ~ ., data=subset, preProcess=c("pca"), method="glm")
fit <- train(diagnosis ~ ., data=subset_w_diagnosis, preProcess=c("pca"), method="glm")
fit
subset
hist(subset)
str(subset)
hist(subset$IL_11)
hist(subset$IL_13)
hist(subset$IL_16)
hist(subset$IL_17E)
qplot(subset)
plot(subset)
subset
tapply(subset, mean)
?apply
?tapply
?sapply
pp <- preProcess(subset,method="pca")
pp
?preProcess
pp <- preProcess(subset,method="pca",thresh=.9)
pp
subset <- subset_w_diagnosis
npca <- glm(diagnosis ~ ., subset)
npca <- lm(diagnosis ~ ., subset)
npca
npca <- train(diagnosis ~ ., method="glm", data=subset)
pca <- train(diagnosis ~., method="glm", preProcess="pca", data=subset)
testset <- testing[,grep("^IL|diagnosis$", colnames(testing))]
testset
pca
npca
npca <- preProcess(subset)
npcaPR <- predict(npca)
npcaPR
npca
predict(npca)
predict(pca)
npca <- train(diagnosis ~ ., method="glm", data=subset)
pca <- train(diagnosis ~ ., method="glm", method="pca", trControl=trainControl(preProcOptions=list(thresh=0.8)), data=subset)
pca <- train(diagnosis ~ ., method="glm", preProcess="pca", trControl=trainControl(preProcOptions=list(thresh=0.8)), data=subset)
confusionMatrix(testing$diagnosis,precit(npca,testing))
confusionMatrix(testing$diagnosis,predict(npca,testing))
confusionMatrix(testing$diagnosis,predict(pca,testing))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
min(training$Superplasticizer)
log(min(training$Superplasticizer))
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
testIndex
nrow(adData)
nrow(testIndex)
training = adData[-testIndex,]
testing = adData[testIndex,]
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
train = createDataPartition(diagnosis,p=0.5,list=F)
train
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
testing
training
training$VEGF = testing$VEGF
dupsBetweenGroups <- function (df, idcol) {
# df: the data frame
# idcol: the column which identifies the group each row belongs to
# Get the data columns to use for finding matches
datacols <- setdiff(names(df), idcol)
# Sort by idcol, then datacols. Save order so we can undo the sorting later.
sortorder <- do.call(order, df)
df <- df[sortorder,]
# Find duplicates within each id group (first copy not marked)
dupWithin <- duplicated(df)
# With duplicates within each group filtered out, find duplicates between groups.
# Need to scan up and down with duplicated() because first copy is not marked.
dupBetween = rep(NA, nrow(df))
dupBetween[!dupWithin] <- duplicated(df[!dupWithin,datacols])
dupBetween[!dupWithin] <- duplicated(df[!dupWithin,datacols], fromLast=TRUE) | dupBetween[!dupWithin]
# ============= Replace NA's with previous non-NA value ==============
# This is why we sorted earlier - it was necessary to do this part efficiently
# Get indexes of non-NA's
goodIdx <- !is.na(dupBetween)
# These are the non-NA values from x only
# Add a leading NA for later use when we index into this vector
goodVals <- c(NA, dupBetween[goodIdx])
# Fill the indices of the output vector with the indices pulled from
# these offsets of goodVals. Add 1 to avoid indexing to zero.
fillIdx <- cumsum(goodIdx)+1
# The original vector, now with gaps filled
dupBetween <- goodVals[fillIdx]
# Undo the original sort
dupBetween[sortorder] <- dupBetween
# Return the vector of which entries are duplicated across groups
return(dupBetween)
}
dupsBetweenGroups(testing, training)
library(AppliedPredictiveModeling)data(AlzheimerDisease)
library(AppliedPredictiveModeling)data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=F)
library(caret)
trainIndex = createDataPartition(diagnosis,p=0.5,list=F)
trainIndex
training = adData[trainIndex,]
testing = adData[-trainIndex,]
train2 = adData[trainIndex,]
test2 = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
train1 = adData[-testIndex,]
test1 = adData[testIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subset <- training[,grep("^IL", colnames(training))]
preProcess(subset, method="pca", thres=0.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
tss <- createDataPartition( y=segmentationOriginal$Case, p=0.7, list=F )
training <- segmentationOriginal[tss,]
testing <- segmentationOriginal[-tss,]
set.seed(125)
training <- segmentationOriginal[Case=='Train',]
training <- segmentationOriginal[segmentationOriginal$Case=='Train',]
testing <- segmentationOriginal[segmentationOriginal$Case=='Test',]
fit <- train( class ~ ., method='rpart', data=training )
training
fit <- train( class ~ ., method='rpart', data=training )
str(training)
data(iris)
tss <- createDataPartition( y=iris$Species, p=0.7, list=F )
trset <- iris[tss,]
ttset <- iris[-tss,]
fit <- train( Species ~ ., method="rpart", data=trset )
str(trset)
fit <- train( Class ~ ., method="rpart", data=training )
?predict
fit
fit$finalModel
?"AppliedPredictiveModeling"
?caret
?"caret"
version(caret)
library(pgmm)
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
ofit <- train( Area ~., method="rpart", data=olive )
ofit
ofit$perfNames
ofit$finalModel
?tree
??tree
newdata = as.data.frame(t(colMeans(olive)))
tree(newdata)
newdata
?predict
predict(ofit, newdata=newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
1:dim(SAheart)[1]
1:dim(SAheart)
set.seed(13234)
colnames(trainSA)
fitSA <- train( chd ~ age + alcohol + typea + ldl, method="glm", family="binomial", data=trainSA )
fitSA
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
predict(fitSA)
predict(fitSA,newdata=testSA)
missCLass(trainSA,predict(fitSA))
missClass(trainSA,predict(fitSA))
missClass(trainSA,predict(fitSA,newdata=trainSA))
colnames(trainSA)
missClass(trainSA)
predict(trainSA)
predict(fitSA)
predict(fitSA)[1]
predict(fitSA) > 0.5
(predict(fitSA) > 0.5) * 1
sum((predict(fitSA) > 0.5) * 1)
sum((predict(fitSA) > 0.5) * 1) / length(predict(fitSA))
sum((predict(fitSA,newdata=testSA) > 0.5) * 1) / length(predict(fitSA,newdata=testSA))
sum((predict(fitSA) > 0.5) * 1) != predict(fitSA)
((predict(fitSA) > 0.5) * 1) != predict(fitSA)
sum((predict(fitSA,newdata=testSA) > 0.5) * 1) / length(predict(fitSA,newdata=testSA))
sum((predict(fitSA) > 0.5) * 1) / length(predict(fitSA))
data(vowel.train)
data(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
vfit <- train( y ~ ., method="rf", data=vowel.train )
vfit <- train( y ~ ., method="rf", data=vowel.train )
varImp()
varImp(vfit)
library(ElemStatLearn)data(SAheart)set.seed(8484)train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)trainSA = SAheart[train,]testSA = SAheart[-train,]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
?glm
fitSA <- glmn( chd ~ age + alcohol + obesity + typea + ldl, family="binomial", data=trainSA )
fitSA <- glm( chd ~ age + alcohol + obesity + typea + ldl, family="binomial", data=trainSA )
fitSA
summary(fitSa)
summary(fitSA)
predict(fitSA)
predict(fitSA) > 0.5
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
fitSA$fitted.values
(predict(fitSA) > 0.5) * 1
sum((predict(fitSA) > 0.5) * 1)
sum((predict(fitSA) > 0.5) * 1) / length(trainSA)
sum((predict(fitSA) > 0.5) * 1) / length(trainSA$chd)
((predict(fitSA) > 0.5) * 1) != trainSA$chd
sum((predict(fitSA) > 0.5) * 1) != trainSA$chd)
sum((predict(fitSA) > 0.5) * 1) != trainSA$chd))
predict(fitSA) > 0.5
(predict(fitSA) > 0.5) * 1
(predict(fitSA) > 0.5) * 1 != trainSA$chd
sum((predict(fitSA) > 0.5) * 1 != trainSA$chd)
sum((predict(fitSA) > 0.5) * 1 != trainSA$chd) / length(trainSA$chd)
sum((predict(fitSA, newdata=testSA) > 0.5) * 1 != testSA$chd) / length(testSA$chd)
missClass(trainSA$chd,fitSA)
missClass(trainSA,fitSA)
missClass(trainSA$chd,predict(fitSA))
missClass(trainSA$chd,predict(fitSA,newdata=testSA))
missClass(testSA$chd,predict(fitSA,newdata=testSA))
missClass(trainSA$chd,predict(fitSA,type=response))
missClass(trainSA$chd,predict(fitSA,type='response'))
missClass(testSA$chd,predict(fitSA,newdata=testSA,type='response'))
load("~/R/PROJECTS/predicting-correct-exercises/workspace.RData")
tst
str(tst)
str(testing)
rft$finalModel
fit <- train( classe ~ . - X - user_name, method="glm", preProcess="pca", data=validation)
library(caret)
fit <- train( classe ~ . - X - user_name, method="glm", preProcess="pca", data=validation)
fit <- train( classe ~ . - X - user_name, method="gbm", preProcess="pca", data=validation)
fit <- train( classe ~ . - X - user_name, method="gbm", data=validation)
m <- abs(cor(validation[,-classe]))
m <- abs(cor(validation[,-c('X','user_name','classe')]))
m <- abs(cor(validation[,!colnames(validation) %in% c('X','user_name','classe')]))
for(n in names(validation)) { ratio <- how_na(validation,n); if(ratio > 0) { print(paste(n, ": ", sprintf("%.2f",ratio))) } }
for(n in names(validation)) { ratio <- how_na(validation,n); if(ratio > 0.9) { print(paste(n, ": ", sprintf("%.2f",ratio))) } }
for(n in names(validation)) { ratio <- how_na(validation,n); if(ratio > 0.9) { print(n) } }
whee <- list()
whee
mostly_na <- function(df,thresh=0.95) {
most_na_list <- list()
for(vn in names(df1)) {
na_ratio <- how_na(df,vn)
if (na_ratio >= thresh){
most_na_list[[length(most_na_list)+1]] <- vn
}
}
most_na_list
}
most_na_list(validation)
mostly_na(validation)
mostly_na <- function(df,thresh=0.95) {
most_na_list <- list()
for(vn in names(df)) {
na_ratio <- how_na(df,vn)
if (na_ratio >= thresh){
most_na_list[[length(most_na_list)+1]] <- vn
}
}
most_na_list
}
mostly_na(validation)
as.list(mostly_na(validation))
c(mostly_na(validation))
cbind(mostly_na(validation))
rbind(mostly_na(validation))
rbind(1,2)
c(1,2)
c(c(1,2),3)
mostly_na <- function(df,thresh=0.95) {
most_na_list <- list()
for(vn in names(df)) {
na_ratio <- how_na(df,vn)
if (na_ratio >= thresh){
c(most_na_list,vn)
}
}
most_na_list
}
mostly_na(validation)
mostly_na <- function(df,thresh=0.95) {
most_na_list <- c()
for(vn in names(df)) {
na_ratio <- how_na(df,vn)
if (na_ratio >= thresh){
c(most_na_list,vn)
}
}
most_na_list
}
mostly_na(validation)
a <- c()
c(a,'1')
a <- c(a,1)
a <- c(a,2)
a
mostly_na <- function(df,thresh=0.9) {
na_list <- c()
for(vn in names(df)) {
na_ratio <- how_na(df,vn)
print(paste(vn,na_ratio))
if (na_ratio >= thresh){
c(na_list,vn)
}
}
most_na_list
}
mostly_na(validation)
mostly_na <- function(df,thresh=0.9) {
na_list <- c()
for(vn in names(df)) {
na_ratio <- how_na(df,vn)
if (na_ratio >= thresh){
c(na_list,vn)
print(paste(vn,"threshold surpassed at",na_ratio))
}
}
na_list
}
mostly_na(validation)
mostly_na <- function(df,thresh=0.9) {
na_list <- c()
for(vn in names(df)) {
na_ratio <- how_na(df,vn)
if (na_ratio >= thresh){
na_list <- c(na_list,vn)
print(paste(vn,"threshold surpassed at",na_ratio))
}
}
na_list
}
mostly_na(validation)
prc <- prcomp(validation[,!colnames(validation) %in% mostly_na(validation)])
ignore <- mostly_na(validation)
fit <- train(classe ~ -ignore, validation, method="rf")
paste(ignore,collapse="-")
paste(ignore,collapse=" - ")
paste("classe ~ . -",paste(ignore,collapse=" - ")
)
as.formula(paste("classe ~ . -",paste(ignore,collapse=" - ")))
simpler_formula <- as.formula(paste("classe ~ . -", paste(mostly_na(validation),collapse=" - ")))
simpler_formula
fit <- train(simpler_formula, validation, method="pca")
fit <- train(simpler_formula, validation, method="glm")
fit <- train(simpler_formula, validation, method="rf")
fit
fit$finalModel
predict(fit,testing)
fit$pred
fit$bestTune
fit$coefnames
save.image("~/R/PROJECTS/predicting-correct-exercises/workspace.RData")
version
save.image("~/R/PROJECTS/predicting-correct-exercises/workspace.RData")
predict(fit,validation)
predict(fit,training)
setwd("~/R/PROJECTS/predicting-correct-exercises")
load("~/R/PROJECTS/predicting-correct-exercises/workspace.RData")
library(ggplot2)
library(grid)
library(gridExtra)
library(knitr)
library(pander)
library(car)
library(caret)
set.seed(7041)
plot_simpler
